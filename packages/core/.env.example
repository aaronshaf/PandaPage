# AI-powered test evaluation configuration
# Copy this file to .env and configure your settings

## AI Provider Configuration
# Works with any OpenAI-compatible endpoint (OpenAI, OpenRouter, Ollama, etc.)

# Base URL for the AI provider
# Examples:
# - Ollama: http://localhost:11434/v1
# - OpenAI: https://api.openai.com/v1
# - OpenRouter: https://openrouter.ai/api/v1
AI_BASE_URL=http://localhost:11434/v1

# API Key for the provider
# - Ollama: Use any value like "ollama" (not validated)
# - OpenAI: Your OpenAI API key (sk-...)
# - OpenRouter: Your OpenRouter API key (sk-or-v1-...)
AI_API_KEY=ollama

# Model to use
# Examples:
# - Ollama: gemma3n:latest, llama3.2:3b, phi4:latest
# - OpenAI: gpt-4o, gpt-4o-mini, gpt-3.5-turbo
# - OpenRouter: meta-llama/llama-3.1-8b-instruct, anthropic/claude-3-haiku, google/gemini-flash-1.5
AI_MODEL=gemma3n:latest

## Test Evaluation Settings

# Minimum similarity score to pass without AI evaluation (0-1)
TEST_MIN_EXACT_MATCH_SCORE=0.95

# Enable AI evaluation for failed tests
TEST_AI_EVALUATION_ENABLED=true

# Enable debug logging for AI evaluation
# AI_DEBUG=true
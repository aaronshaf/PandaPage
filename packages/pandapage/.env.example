# AI-powered test evaluation configuration
# Copy this file to .env and configure your settings

# Choose AI provider: "ollama" (default) or "openrouter"
# If OPENROUTER_API_KEY is set, it will default to openrouter
AI_PROVIDER=ollama

# Model to use (this overrides provider-specific model settings)
# AI_MODEL=llama3.2:3b

## Ollama Configuration (default provider)
OLLAMA_HOST=http://localhost:11434
OLLAMA_MODEL=gemma3n:latest

## OpenRouter Configuration (alternative provider)
# Get your API key from https://openrouter.ai/keys
# OPENROUTER_API_KEY=sk-or-v1-...
# OPENROUTER_MODEL=meta-llama/llama-3.1-8b-instruct

# Popular OpenRouter models for text comparison:
# - meta-llama/llama-3.1-8b-instruct (fast, good quality)
# - anthropic/claude-3-haiku (very fast, high quality)
# - google/gemini-flash-1.5 (fast, good for structured output)
# - openai/gpt-3.5-turbo (reliable, good at following instructions)

# Test evaluation settings
# Minimum similarity score to pass without AI evaluation (0-1)
TEST_MIN_EXACT_MATCH_SCORE=0.95

# Enable AI evaluation for failed tests
TEST_AI_EVALUATION_ENABLED=true
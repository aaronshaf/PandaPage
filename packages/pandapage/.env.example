# Ollama Configuration for AI-powered test evaluation
# Copy this file to .env and configure your settings

# Ollama API endpoint (default: http://localhost:11434)
OLLAMA_HOST=http://localhost:11434

# Model to use for text comparison (e.g., phi4, llama2, mistral, codellama)
OLLAMA_MODEL=phi4:latest

# Optional: API key if using OpenAI-compatible endpoint
# OLLAMA_API_KEY=

# Optional: Use OpenRouter instead of Ollama
# OPENROUTER_API_KEY=
# OPENROUTER_MODEL=meta-llama/llama-2-70b-chat

# Test evaluation settings
# Minimum similarity score to pass without AI evaluation (0-1)
TEST_MIN_EXACT_MATCH_SCORE=0.95

# Enable AI evaluation for failed tests
TEST_AI_EVALUATION_ENABLED=true